{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeedbackType = Literal['mixed_vector', 'pure_vector', 'bandit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game:\n",
    "    def __init__(self, payoffs, feedback_type: FeedbackType = 'mixed_vector'):\n",
    "        self.payoffs = payoffs\n",
    "        self.feedback_type = feedback_type\n",
    "\n",
    "    def __str__(self):\n",
    "        pass\n",
    "\n",
    "    def update_values(self, \n",
    "                      strategies,\n",
    "                      values, \n",
    "                      learning_rate = 0.1,\n",
    "                      feedback_type: FeedbackType = None):\n",
    "      if feedback_type is None:\n",
    "          feedback_type = self.feedback_type\n",
    "      \n",
    "      feedbacks = self.get_feedbacks(strategies, feedback_type)\n",
    "      for i in range(len(feedbacks)):\n",
    "          \n",
    "          values[i] += learning_rate * feedbacks[i]\n",
    "\n",
    "      return values\n",
    "\n",
    "    def get_strategies(self, values, dynamics = \"exponential-weight\"):\n",
    "        exponential_weights = [[np.exp(strategy_value) for strategy_value in value] for value in values]  \n",
    "        sum_exponential_weights = [np.sum(exponential_weight) for exponential_weight in exponential_weights]\n",
    "        updated_strategies = [[strategy_weight/sum_exponential_weights[player] \\\n",
    "                                   for strategy_weight in exponential_weight] \\\n",
    "                                   for player, exponential_weight in enumerate(exponential_weights)]\n",
    "        return updated_strategies\n",
    "    \n",
    "    def get_feedbacks(self, strategies, feedback_type: FeedbackType = None):\n",
    "      if feedback_type is None:\n",
    "          feedback_type = self.feedback_type\n",
    "\n",
    "      if feedback_type == 'mixed_vector':\n",
    "          feedback_0 = np.matmul(self.payoffs[0], strategies[1])\n",
    "          feedback_1 = np.matmul(self.payoffs[1].T, strategies[0])\n",
    "          return [feedback_0, feedback_1]\n",
    "      \n",
    "      action_0 = Game._sample_from_distribution(strategies[0])\n",
    "      action_1 = Game._sample_from_distribution(strategies[1])\n",
    "      \n",
    "      if feedback_type == 'pure_vector':\n",
    "          feedback_0 = np.array(self.payoffs[0][action_1])\n",
    "          feedback_1 = np.array(self.payoffs[1][action_0])\n",
    "\n",
    "          return [feedback_0, feedback_1]\n",
    "      \n",
    "      if feedback_type == 'bandit':\n",
    "          feedback_0 = np.array([self.payoffs[0][action_1][0]*(action_0 == 0)/strategies[0][0], \n",
    "                        self.payoffs[0][action_1][0]*(action_0 == 1)/strategies[0][1]])\n",
    "          feedback_1 = np.array([self.payoffs[1][action_0][0]*(action_1 == 0)/strategies[1][0], \n",
    "                        self.payoffs[1][action_0][1]*(action_1 == 1)/strategies[1][1]])\n",
    "          return [feedback_0, feedback_1]\n",
    "      \n",
    "\n",
    "    @staticmethod\n",
    "    def _sample_from_distribution(distribution):\n",
    "        return np.random.choice(len(distribution), p=distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1,-5], [0, -3]])\n",
    "B = np.array([[-1,0], [-5, -3]])  \n",
    "\n",
    "strategies = [[0.9, 0.1], [0.7, 0.3]]\n",
    "values = [[0, 0], [0, 0]]\n",
    "\n",
    "game = Game(np.array([A,B]), feedback_type='mixed_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.22, -0.09]), array([-0.14, -0.03])]\n"
     ]
    }
   ],
   "source": [
    "history = [[], []]\n",
    "new_strategies = strategies\n",
    "new_values = values\n",
    "\n",
    "for i in range(100):\n",
    "  new_values = game.update_values(new_strategies, values = new_values, learning_rate=0.1)\n",
    "  new_strategies = game.get_strategies(new_values)\n",
    "  \n",
    "  history[0].append(new_strategies[0])\n",
    "  history[1].append(new_strategies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.286822933877988e-09, 0.999999996713177]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[0][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
